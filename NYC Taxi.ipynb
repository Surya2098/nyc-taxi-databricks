{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14cdeda3-1a4a-41be-8e34-54840ee38694",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Big Data Analysis of NYC Taxi Trips with PySpark\n"
     ]
    }
   ],
   "source": [
    "print(\"Big Data Analysis of NYC Taxi Trips with PySpark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a2d0afc-4266-400f-a283-89a7ce118bf2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+\n|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|Airport_fee|cbd_congestion_fee|\n+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+\n|       2| 2025-02-01 00:12:18|  2025-02-01 00:32:33|              3|         3.12|         1|                 N|         246|          79|           1|       19.8|  1.0|    0.5|      5.11|         0.0|                  1.0|       30.66|                 2.5|          0|              0.75|\n|       2| 2025-02-01 00:40:04|  2025-02-01 00:49:15|              1|          1.4|         1|                 N|         114|          79|           1|       10.0|  1.0|    0.5|      3.15|         0.0|                  1.0|        18.9|                 2.5|          0|              0.75|\n|       1| 2025-02-01 00:06:09|  2025-02-01 00:11:51|              0|          0.4|         1|                 N|         211|         144|           1|        6.5| 4.25|    0.5|       1.0|         0.0|                  1.0|       13.25|                 2.5|          0|              0.75|\n|       1| 2025-02-01 00:15:13|  2025-02-01 00:20:19|              0|          0.7|         1|                 N|         113|         249|           1|        7.2| 4.25|    0.5|       2.0|         0.0|                  1.0|       14.95|                 2.5|          0|              0.75|\n|       2| 2025-02-01 00:02:52|  2025-02-01 00:20:25|              1|         4.19|         1|                 N|         113|         263|           1|       19.8|  1.0|    0.5|      5.11|         0.0|                  1.0|       30.66|                 2.5|          0|              0.75|\n+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "#Upload & Load the Dataset\n",
    "\n",
    "# Mount the uploaded dataset in Databricks FileStore\n",
    "file_path = \"dbfs:/FileStore/tables/yellow_tripdata_2025_02.csv\"\n",
    "\n",
    "# Load the CSV using PySpark\n",
    "df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(file_path)\n",
    "\n",
    "# Preview\n",
    "df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a246b1a-cf6c-489f-ac9b-51ff140cf0e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+------------------+------------+\n|    pickup_datetime|   dropoff_datetime|trip_duration_mins|is_rush_hour|\n+-------------------+-------------------+------------------+------------+\n|2025-02-01 00:12:18|2025-02-01 00:32:33|             20.25|           0|\n|2025-02-01 00:40:04|2025-02-01 00:49:15|              9.18|           0|\n|2025-02-01 00:06:09|2025-02-01 00:11:51|               5.7|           0|\n|2025-02-01 00:15:13|2025-02-01 00:20:19|               5.1|           0|\n|2025-02-01 00:02:52|2025-02-01 00:20:25|             17.55|           0|\n+-------------------+-------------------+------------------+------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "#Feature Engineering – Add Trip Duration & Rush Hour Flag\n",
    "\n",
    "from pyspark.sql.functions import col, to_timestamp, hour, when, round\n",
    "\n",
    "# Convert timestamps\n",
    "df = df.withColumn(\"pickup_datetime\", to_timestamp(\"tpep_pickup_datetime\")) \\\n",
    "       .withColumn(\"dropoff_datetime\", to_timestamp(\"tpep_dropoff_datetime\"))\n",
    "\n",
    "# Trip duration in minutes\n",
    "df = df.withColumn(\"trip_duration_mins\", \n",
    "                   round((col(\"dropoff_datetime\").cast(\"long\") - col(\"pickup_datetime\").cast(\"long\")) / 60, 2))\n",
    "\n",
    "# Rush Hour flag (7–9 AM or 4–6 PM)\n",
    "df = df.withColumn(\"pickup_hour\", hour(\"pickup_datetime\")) \\\n",
    "       .withColumn(\"is_rush_hour\", when((col(\"pickup_hour\").between(7, 9)) | (col(\"pickup_hour\").between(16, 18)), 1).otherwise(0))\n",
    "\n",
    "df.select(\"pickup_datetime\", \"dropoff_datetime\", \"trip_duration_mins\", \"is_rush_hour\").show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1396276-45ad-45fc-9b46-85ef81c7981b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+------------+------------+--------------+\n|VendorID|is_rush_hour|avg_distance|avg_duration|avg_passengers|\n+--------+------------+------------+------------+--------------+\n|       1|           0|        3.07|       15.78|          1.14|\n|       7|           1|        2.06|         0.0|          1.15|\n|       1|           1|        2.86|       16.64|           1.1|\n|       2|           1|        7.99|       15.85|          1.29|\n|       2|           0|        6.33|       14.99|          1.33|\n|       7|           0|        2.31|         0.0|          1.23|\n|       6|           1|        8.39|       32.24|          null|\n|       6|           0|        8.65|       28.58|          null|\n+--------+------------+------------+------------+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "#Aggregation\n",
    "\n",
    "from pyspark.sql.functions import avg, round\n",
    "\n",
    "# Average trip duration and distance by vendor and rush hour\n",
    "agg_df = df.groupBy(\"VendorID\", \"is_rush_hour\").agg(\n",
    "    round(avg(\"trip_distance\"), 2).alias(\"avg_distance\"),\n",
    "    round(avg(\"trip_duration_mins\"), 2).alias(\"avg_duration\"),\n",
    "    round(avg(\"passenger_count\"), 2).alias(\"avg_passengers\")\n",
    ")\n",
    "\n",
    "agg_df.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f878ddd-2b0c-41f6-afc2-175a95cedb9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+-------------------+-------------------+------------------+-----------+------------+\n|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|Airport_fee|cbd_congestion_fee|    pickup_datetime|   dropoff_datetime|trip_duration_mins|pickup_hour|is_rush_hour|\n+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+-------------------+-------------------+------------------+-----------+------------+\n|       1| 2025-02-01 00:32:24|  2025-02-01 00:40:49|              2|          1.1|         1|                 N|         233|         164|           2|        9.3| 4.25|    0.5|       0.0|         0.0|                  1.0|       15.05|                 2.5|          0|              0.75|2025-02-01 00:32:24|2025-02-01 00:40:49|              8.42|          0|           0|\n|       1| 2025-02-01 00:23:59|  2025-02-01 00:41:09|              2|          3.2|         1|                 N|         144|         100|           1|       18.4| 4.25|    0.5|       4.0|         0.0|                  1.0|       28.15|                 2.5|          0|              0.75|2025-02-01 00:23:59|2025-02-01 00:41:09|             17.17|          0|           0|\n|       1| 2025-02-01 00:15:03|  2025-02-01 00:27:06|              2|          1.6|         1|                 N|         158|          79|           1|       10.7| 4.25|    0.5|       4.1|         0.0|                  1.0|       20.55|                 2.5|          0|              0.75|2025-02-01 00:15:03|2025-02-01 00:27:06|             12.05|          0|           0|\n|       1| 2025-02-01 00:32:59|  2025-02-01 00:45:06|              4|          1.4|         1|                 N|          79|         249|           2|       11.4| 4.25|    0.5|       0.0|         0.0|                  1.0|       17.15|                 2.5|          0|              0.75|2025-02-01 00:32:59|2025-02-01 00:45:06|             12.12|          0|           0|\n|       1| 2025-02-01 00:16:41|  2025-02-01 00:39:34|              2|          6.8|         1|                 N|         148|         263|           1|       30.3| 4.25|    0.5|       4.0|         0.0|                  1.0|       40.05|                 2.5|          0|              0.75|2025-02-01 00:16:41|2025-02-01 00:39:34|             22.88|          0|           0|\n+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+-------------------+-------------------+------------------+-----------+------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "#Performance Optimizations\n",
    "\n",
    "# Repartition based on VendorID\n",
    "df = df.repartition(\"VendorID\")\n",
    "\n",
    "# Caching the dataframe in memory\n",
    "df.cache()\n",
    "df.count()  # Triggers caching\n",
    "\n",
    "# Apply a filter to test filter pushdown (assuming zone is available)\n",
    "filtered_df = df.filter(col(\"passenger_count\") > 1)\n",
    "filtered_df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ceb285d2-373e-435d-9742-f0b404387b0b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Write to Parquet and Delta Lake Formats\n",
    "\n",
    "# Save as Parquet\n",
    "df.write.mode(\"overwrite\").parquet(\"/tmp/nyc_taxi_parquet\")\n",
    "\n",
    "# Save as Delta Lake\n",
    "df.write.format(\"delta\").mode(\"overwrite\").save(\"/tmp/nyc_taxi_delta\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b826545a-30ed-436b-bc16-24ba01e0d056",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+\n|VendorID|  trips|\n+--------+-------+\n|       2|2817803|\n|       1| 754990|\n|       6|    330|\n|       7|   4420|\n+--------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "#Created SQL Table from Delta Lake\n",
    "\n",
    "# Register Delta Table\n",
    "spark.sql(\"DROP TABLE IF EXISTS nyc_taxi_delta\")\n",
    "spark.sql(\"CREATE TABLE nyc_taxi_delta USING DELTA LOCATION '/tmp/nyc_taxi_delta'\")\n",
    "\n",
    "# Query using Spark SQL\n",
    "spark.sql(\"SELECT VendorID, COUNT(*) as trips FROM nyc_taxi_delta GROUP BY VendorID\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "06d161ca-ff5d-4ef1-99e3-f8f918d466a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "NYC Taxi",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}